---
layout              : page
title               : "Submissions"
permalink           : "/submissions/"
---
We welcome papers on the topic of reliance and accountability in human-AI interactions, with a specific focus on under- or overreliance on LLMs. Submissions may fall into any of the following areas:
1. **Theory and research methods**: computational, psychological, cognitive, and
formal models of reliance and accountability;
2. **Technical**: novel algorithmic approaches, system descriptions, metrics, and experimental paradigms to measure reliance and accountability;
3. **Design**: interaction design to modulate reliance and establish accountability;
4. **User studies**: empirical studies into reliance and accountability in human-LLM interaction.
   
This list is non-exhaustive and we welcome any relevant work.

ORIGen will accept both archival *original research* and non-archival *cross-submissions*. Original research papers may be *long papers* (9 pages) or *short papers* (5 pages) prepared according to the [COLM template](https://github.com/COLM-org/Template/archive/refs/tags/2025.zip). These submissions will undergo *double-blind* review and so must be fully anonymized.  Accepted original research papers will be published in a proceedings after the workshop on an open-access proceedings platform such as [CEUR-WS](https://ceur-ws.org). Publishing in the proceedings of ORIGen will not preclude submission of the published work in the same or updated form to future venues, unless otherwise indicated by the other venue. We will also welcome cross-submissions from other venues (e.g., *ACL or the COLM main conference) who wish to present their work at ORIGen. These submissions will be assessed for relevance and fit for ORIGen, and may be either single-blind or double-blind.

Accepted papers will be presented as posters. Please see the [schedule](https://origen-workshop.github.io/programme/) for details.
